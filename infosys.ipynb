{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e13f7c",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fastapi uvicorn pyngrok xgboost scikit-learn pandas nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b890d",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c9cba",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca000df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('/content/sample_data/Phishing.csv')\n",
    "\n",
    "# Rename target column\n",
    "df.rename(columns={'CLASS_LABEL': 'label'}, inplace=True)\n",
    "\n",
    "# Basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")\n",
    "print(f\"\\nNull values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce42265",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5608098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(['id', 'label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nFeatures ({X_train.shape[1]}): {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f49a8b5",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02522a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60204bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "models_performance = {\n",
    "    'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, rf_pred),\n",
    "        accuracy_score(y_test, lr_pred),\n",
    "        accuracy_score(y_test, xgb_pred)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, rf_pred),\n",
    "        precision_score(y_test, lr_pred),\n",
    "        precision_score(y_test, xgb_pred)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, rf_pred),\n",
    "        recall_score(y_test, lr_pred),\n",
    "        recall_score(y_test, xgb_pred)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, rf_pred),\n",
    "        f1_score(y_test, lr_pred),\n",
    "        f1_score(y_test, xgb_pred)\n",
    "    ]\n",
    "}\n",
    "\n",
    "perf_df = pd.DataFrame(models_performance)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(perf_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model_idx = perf_df['F1-Score'].idxmax()\n",
    "print(f\"\\nğŸ† Best Model: {perf_df.loc[best_model_idx, 'Model']} (F1-Score: {perf_df.loc[best_model_idx, 'F1-Score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14585128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Bar chart for all metrics\n",
    "ax1 = axes[0, 0]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(perf_df['Model']))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax1.bar(x + i*width, perf_df[metric], width, label=metric)\n",
    "\n",
    "ax1.set_xlabel('Models', fontweight='bold')\n",
    "ax1.set_ylabel('Score', fontweight='bold')\n",
    "ax1.set_title('All Metrics Comparison')\n",
    "ax1.set_xticks(x + width * 1.5)\n",
    "ax1.set_xticklabels(perf_df['Model'])\n",
    "ax1.legend()\n",
    "ax1.set_ylim([0, 1.05])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Grouped bar chart for better comparison\n",
    "ax2 = axes[0, 1]\n",
    "perf_df_melted = pd.melt(perf_df, id_vars=['Model'], var_name='Metric', value_name='Score')\n",
    "models = perf_df['Model'].unique()\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x2 = np.arange(len(metric_names))\n",
    "width2 = 0.25\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_data = perf_df_melted[perf_df_melted['Model'] == model]\n",
    "    scores = model_data['Score'].values\n",
    "    ax2.bar(x2 + i*width2, scores, width2, label=model)\n",
    "\n",
    "ax2.set_xlabel('Metrics', fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontweight='bold')\n",
    "ax2.set_title('Metrics by Model')\n",
    "ax2.set_xticks(x2 + width2)\n",
    "ax2.set_xticklabels(metric_names)\n",
    "ax2.legend()\n",
    "ax2.set_ylim([0, 1.05])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Heatmap\n",
    "ax3 = axes[1, 0]\n",
    "heatmap_data = perf_df.set_index('Model').T\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.4f', cmap='YlGnBu', ax=ax3, \n",
    "            cbar_kws={'label': 'Score'}, linewidths=0.5)\n",
    "ax3.set_title('Performance Heatmap')\n",
    "ax3.set_xlabel('')\n",
    "ax3.set_ylabel('Metrics', fontweight='bold')\n",
    "\n",
    "# 4. Radar chart\n",
    "ax4 = axes[1, 1]\n",
    "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4, projection='polar')\n",
    "for idx, model in enumerate(perf_df['Model']):\n",
    "    values = perf_df.iloc[idx][['Accuracy', 'Precision', 'Recall', 'F1-Score']].tolist()\n",
    "    values += values[:1]\n",
    "    ax4.plot(angles, values, 'o-', linewidth=2, label=model)\n",
    "    ax4.fill(angles, values, alpha=0.15)\n",
    "\n",
    "ax4.set_xticks(angles[:-1])\n",
    "ax4.set_xticklabels(categories)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_title('Radar Chart Comparison', pad=20)\n",
    "ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Highest Accuracy:  {perf_df.loc[perf_df['Accuracy'].idxmax(), 'Model']} ({perf_df['Accuracy'].max():.4f})\")\n",
    "print(f\"Highest Precision: {perf_df.loc[perf_df['Precision'].idxmax(), 'Model']} ({perf_df['Precision'].max():.4f})\")\n",
    "print(f\"Highest Recall:    {perf_df.loc[perf_df['Recall'].idxmax(), 'Model']} ({perf_df['Recall'].max():.4f})\")\n",
    "print(f\"Highest F1-Score:  {perf_df.loc[perf_df['F1-Score'].idxmax(), 'Model']} ({perf_df['F1-Score'].max():.4f})\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e5e8e",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a956a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "print(\"Performing hyperparameter tuning on XGBoost...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1-score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get tuned model\n",
    "tuned_model = grid_search.best_estimator_\n",
    "tuned_pred = tuned_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nTuned Model Performance:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, tuned_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, tuned_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, tuned_pred):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, tuned_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7efd25",
   "metadata": {},
   "source": [
    "## 7. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tuned model\n",
    "model_filename = 'phishing_detector_model.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(tuned_model, f)\n",
    "\n",
    "print(f\"âœ… Model saved as '{model_filename}'\")\n",
    "\n",
    "# Verify the save\n",
    "with open(model_filename, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    \n",
    "test_pred = loaded_model.predict(X_test[:5])\n",
    "print(f\"\\nâœ… Model loaded successfully and verified\")\n",
    "print(f\"Sample predictions: {test_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eda647",
   "metadata": {},
   "source": [
    "## 8. Feature Extraction Function for URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30174c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sensitive keywords\n",
    "SENSITIVE_WORDS = ['login', 'account', 'verify', 'update', 'bank', 'paypal', 'secure', 'signin', 'confirm']\n",
    "\n",
    "def extract_features_from_url(url: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extract 48 features from a URL string for phishing detection.\n",
    "    \n",
    "    Args:\n",
    "        url: URL string to analyze\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series with 48 features aligned with training data\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    scheme = parsed_url.scheme.lower() if parsed_url.scheme else ''\n",
    "    hostname = parsed_url.hostname if parsed_url.hostname else ''\n",
    "    path = parsed_url.path\n",
    "    query = parsed_url.query\n",
    "    \n",
    "    # URL-based features\n",
    "    features['NumDots'] = float(url.count('.'))\n",
    "    features['SubdomainLevel'] = float(hostname.count('.'))\n",
    "    features['PathLevel'] = float(path.count('/'))\n",
    "    features['UrlLength'] = float(len(url))\n",
    "    features['NumDash'] = float(url.count('-'))\n",
    "    features['NumDashInHostname'] = float(hostname.count('-'))\n",
    "    features['AtSymbol'] = float(1 if '@' in url else 0)\n",
    "    features['TildeSymbol'] = float(1 if '~' in url else 0)\n",
    "    features['NumUnderscore'] = float(url.count('_'))\n",
    "    features['NumPercent'] = float(url.count('%'))\n",
    "    features['NumQueryComponents'] = float(query.count('&') + (1 if query else 0))\n",
    "    features['NumAmpersand'] = float(url.count('&'))\n",
    "    features['NumHash'] = float(1 if '#' in url else 0)\n",
    "    features['NumNumericChars'] = float(sum(c.isdigit() for c in url))\n",
    "    features['NoHttps'] = float(1 if scheme == 'http' else 0)\n",
    "    \n",
    "    # IP address detection\n",
    "    ip_pattern = r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\"\n",
    "    features['IpAddress'] = float(1 if re.match(ip_pattern, hostname) else 0)\n",
    "    \n",
    "    # Domain features\n",
    "    features['HttpsInHostname'] = float(1 if 'https' in hostname else 0)\n",
    "    features['HostnameLength'] = float(len(hostname))\n",
    "    features['PathLength'] = float(len(path))\n",
    "    features['QueryLength'] = float(len(query))\n",
    "    features['DoubleSlashInPath'] = float(1 if '//' in path and not path.startswith('//') else 0)\n",
    "    features['NumSensitiveWords'] = float(sum(1 for word in SENSITIVE_WORDS if word in url.lower()))\n",
    "    \n",
    "    # Placeholder features (not computable without HTML content)\n",
    "    features['RandomString'] = 0.0\n",
    "    features['DomainInSubdomains'] = 0.0\n",
    "    features['DomainInPaths'] = 0.0\n",
    "    features['EmbeddedBrandName'] = 0.0\n",
    "    features['PctExtHyperlinks'] = 0.0\n",
    "    features['PctExtResourceUrls'] = 0.0\n",
    "    features['ExtFavicon'] = 0.0\n",
    "    features['InsecureForms'] = 0.0\n",
    "    features['RelativeFormAction'] = 0.0\n",
    "    features['ExtFormAction'] = 0.0\n",
    "    features['AbnormalFormAction'] = 0.0\n",
    "    features['PctNullSelfRedirectHyperlinks'] = 0.0\n",
    "    features['FrequentDomainNameMismatch'] = 0.0\n",
    "    features['FakeLinkInStatusBar'] = 0.0\n",
    "    features['RightClickDisabled'] = 0.0\n",
    "    features['PopUpWindow'] = 0.0\n",
    "    features['SubmitInfoToEmail'] = 0.0\n",
    "    features['IframeOrFrame'] = 0.0\n",
    "    features['MissingTitle'] = 0.0\n",
    "    features['ImagesOnlyInForm'] = 0.0\n",
    "    features['SubdomainLevelRT'] = 1.0\n",
    "    features['UrlLengthRT'] = 0.0\n",
    "    features['PctExtResourceUrlsRT'] = 1.0\n",
    "    features['AbnormalExtFormActionR'] = 1.0\n",
    "    features['ExtMetaScriptLinkRT'] = -1.0\n",
    "    features['PctExtNullSelfRedirectHyperlinksRT'] = 1.0\n",
    "    \n",
    "    # Return as Series aligned with training features\n",
    "    feature_series = pd.Series(features)\n",
    "    return feature_series.reindex(X_train.columns, fill_value=0.0)\n",
    "\n",
    "# Test the function\n",
    "test_url = \"https://www.google.com/search?q=test\"\n",
    "test_features = extract_features_from_url(test_url)\n",
    "print(f\"âœ… Feature extraction function ready\")\n",
    "print(f\"Extracted {len(test_features)} features from URL\")\n",
    "print(f\"Sample: NumDots={test_features['NumDots']}, UrlLength={test_features['UrlLength']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aba59b",
   "metadata": {},
   "source": [
    "## 9. Setup FastAPI Application with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import socket\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from threading import Thread\n",
    "\n",
    "# Allow nested event loops (required for Colab)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(title=\"Phishing Detection API\", version=\"1.0\")\n",
    "\n",
    "# Enable CORS for frontend integration\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # In production, specify your frontend domain\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Request model\n",
    "class URLInput(BaseModel):\n",
    "    url: str\n",
    "\n",
    "# Response model\n",
    "class PredictionResponse(BaseModel):\n",
    "    url: str\n",
    "    prediction: int\n",
    "    result: str\n",
    "    confidence: str\n",
    "\n",
    "# Load the trained model\n",
    "with open('phishing_detector_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Phishing Detection API\",\n",
    "        \"status\": \"active\",\n",
    "        \"endpoints\": {\n",
    "            \"/predict\": \"POST - Predict if a URL is phishing\",\n",
    "            \"/health\": \"GET - Health check\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "async def predict_phishing(url_input: URLInput):\n",
    "    \"\"\"\n",
    "    Predict if a URL is phishing or legitimate.\n",
    "    \n",
    "    Returns:\n",
    "    - prediction: 0 (legitimate) or 1 (phishing)\n",
    "    - result: 'Legitimate' or 'Phishing'\n",
    "    - confidence: Model confidence level\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract features from URL\n",
    "        features = extract_features_from_url(url_input.url)\n",
    "        \n",
    "        # Convert to DataFrame for prediction\n",
    "        input_df = pd.DataFrame([features])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = int(model.predict(input_df)[0])\n",
    "        \n",
    "        # Get probability for confidence\n",
    "        proba = model.predict_proba(input_df)[0]\n",
    "        confidence = f\"{max(proba) * 100:.2f}%\"\n",
    "        \n",
    "        result = \"Phishing\" if prediction == 1 else \"Legitimate\"\n",
    "        \n",
    "        return {\n",
    "            \"url\": url_input.url,\n",
    "            \"prediction\": prediction,\n",
    "            \"result\": result,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Prediction failed: {str(e)}\")\n",
    "\n",
    "print(\"âœ… FastAPI application configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738a0a0",
   "metadata": {},
   "source": [
    "## 10. Start the API Server with ngrok Tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daeffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set your ngrok auth token here\n",
    "# Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_AUTH_TOKEN_HERE\"  # Replace with your token\n",
    "\n",
    "# Kill any existing ngrok tunnels\n",
    "ngrok.kill()\n",
    "\n",
    "# Set ngrok auth token\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "# Start uvicorn server in a separate thread\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n",
    "\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(3)\n",
    "\n",
    "# Create ngrok tunnel\n",
    "public_url = ngrok.connect(8000).public_url\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ API SERVER IS RUNNING!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“¡ Public URL: {public_url}\")\n",
    "print(f\"\\nğŸ”— API Endpoints:\")\n",
    "print(f\"   - Root:    {public_url}/\")\n",
    "print(f\"   - Health:  {public_url}/health\")\n",
    "print(f\"   - Predict: {public_url}/predict (POST)\")\n",
    "print(f\"\\nğŸ“ API Documentation: {public_url}/docs\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nğŸ’¡ Use this URL in your frontend to make predictions!\")\n",
    "print(\"\\nâš ï¸  Keep this cell running to maintain the server\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d8f66",
   "metadata": {},
   "source": [
    "## 11. Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the API with sample URLs\n",
    "import requests\n",
    "import json\n",
    "\n",
    "API_URL = public_url + \"/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Test URLs\n",
    "test_urls = [\n",
    "    \"https://www.google.com\",\n",
    "    \"http://paypal-secure.verify-account.com/login\",\n",
    "    \"https://github.com/microsoft/vscode\",\n",
    "    \"http://192.168.1.1/admin/verify?user=admin\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª TESTING API\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for test_url in test_urls:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            API_URL,\n",
    "            headers=headers,\n",
    "            data=json.dumps({\"url\": test_url}),\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            status_icon = \"ğŸš¨\" if result['prediction'] == 1 else \"âœ…\"\n",
    "            print(f\"{status_icon} URL: {test_url}\")\n",
    "            print(f\"   Result: {result['result']} (Confidence: {result['confidence']})\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"âŒ Error testing {test_url}: {response.status_code}\")\n",
    "            print()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Exception testing {test_url}: {str(e)}\")\n",
    "        print()\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0013536",
   "metadata": {},
   "source": [
    "## 12. Frontend Integration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘              FRONTEND INTEGRATION GUIDE                        â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "JavaScript/React Example:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "const checkURL = async (url) => {\n",
    "  try {\n",
    "    const response = await fetch('\"\"\" + public_url + \"\"\"/predict', {\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json',\n",
    "      },\n",
    "      body: JSON.stringify({ url: url })\n",
    "    });\n",
    "    \n",
    "    const data = await response.json();\n",
    "    console.log('Prediction:', data.result);\n",
    "    console.log('Confidence:', data.confidence);\n",
    "    return data;\n",
    "  } catch (error) {\n",
    "    console.error('Error:', error);\n",
    "  }\n",
    "};\n",
    "\n",
    "// Usage\n",
    "checkURL('https://example.com').then(result => {\n",
    "  if (result.prediction === 1) {\n",
    "    alert('âš ï¸ Warning: This URL appears to be PHISHING!');\n",
    "  } else {\n",
    "    alert('âœ… This URL appears to be legitimate.');\n",
    "  }\n",
    "});\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Python Example:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "import requests\n",
    "\n",
    "def check_url(url):\n",
    "    response = requests.post(\n",
    "        '\"\"\" + public_url + \"\"\"/predict',\n",
    "        json={'url': url}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "result = check_url('https://example.com')\n",
    "print(f\"Result: {result['result']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cURL Example:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "curl -X POST \"\"\" + public_url + \"\"\"/predict \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{\"url\": \"https://example.com\"}'\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Response Format:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "{\n",
    "  \"url\": \"https://example.com\",\n",
    "  \"prediction\": 0,              // 0 = Legitimate, 1 = Phishing\n",
    "  \"result\": \"Legitimate\",       // Human-readable result\n",
    "  \"confidence\": \"98.75%\"        // Model confidence\n",
    "}\n",
    "\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88616164",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Important Points:\n",
    "\n",
    "1. **Keep the server cell running** - The API will stop if you interrupt the cell\n",
    "2. **ngrok URL changes** - Each time you restart, you'll get a new public URL\n",
    "3. **Free tier limits** - ngrok free tier has connection limits\n",
    "4. **CORS enabled** - The API accepts requests from any origin (adjust for production)\n",
    "5. **Model Features** - The API extracts 48 features from each URL automatically\n",
    "\n",
    "### Security Recommendations:\n",
    "\n",
    "- In production, replace `allow_origins=[\"*\"]` with your specific frontend domain\n",
    "- Add rate limiting to prevent abuse\n",
    "- Implement authentication if needed\n",
    "- Use HTTPS in production\n",
    "- Consider deploying to a cloud platform for better reliability\n",
    "\n",
    "### Model Performance:\n",
    "\n",
    "- The tuned XGBoost model achieves ~98-99% accuracy\n",
    "- Features include URL structure, domain characteristics, and suspicious patterns\n",
    "- Some features require HTML content analysis (set to defaults in this version)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Integrate with your frontend application\n",
    "2. Monitor API performance and errors\n",
    "3. Collect feedback and retrain model periodically\n",
    "4. Consider deploying to a production server (AWS, GCP, Azure, Heroku, etc.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
